{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6fcd79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "text = [\n",
    "\"Deep learning is a subset of machine learning\", \n",
    "\"Neural networks are a key component of deep learning\",\n",
    "\"Supervised learning involves training a model on labeled data\",\n",
    "\"Unsupervised learning finds patterns in data without labels\",\n",
    "\"Reinforcement learning is based on rewards and punishments\",\n",
    "\"Transfer learning allows models to leverage pre-trained knowledge\"\n",
    "]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd5e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[342, 194, 489, 559, 236, 578, 626, 194], [985, 811, 865, 559, 177, 749, 578, 342, 194], [511, 194, 771, 800, 559, 46, 660, 130, 303], [183, 194, 186, 851, 706, 303, 1, 75], [585, 194, 489, 743, 660, 136, 29, 596], [8, 194, 386, 645, 528, 724, 291, 46, 777]]\n"
     ]
    }
   ],
   "source": [
    "# Define vocabulary size\n",
    "vocab_size = 1000\n",
    "# One-hot encode the text\n",
    "onehot_repr = [one_hot(words, vocab_size) for words in text]\n",
    "print(onehot_repr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9dc63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[966, 227, 626, 194],\n",
       " [966, 227, 342, 194],\n",
       " [626, 194, 489, 504],\n",
       " [342, 194, 489, 475],\n",
       " [985, 811, 865, 948],\n",
       " [662, 365, 187, 645, 221]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small sentcess for testing\n",
    "sentences = [\n",
    "    \"I love machine learning\",\n",
    "    \"I love deep learning\",\n",
    "    \"Machine learning is fun\",\n",
    "    \"Deep learning is fascinating\",\n",
    "    \"Neural networks are powerful\",\n",
    "    \"Keras makes building models easy\"\n",
    "]\n",
    "# One-hot encode the test sentences\n",
    "test_onehot = [one_hot(words, vocab_size) for words in sentences]\n",
    "test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380f474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Embedding Representation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fee411b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 342 194 489 559 236 578 626 194]\n",
      " [  0 985 811 865 559 177 749 578 342 194]\n",
      " [  0 511 194 771 800 559  46 660 130 303]\n",
      " [  0   0 183 194 186 851 706 303   1  75]\n",
      " [  0   0 585 194 489 743 660 136  29 596]\n",
      " [  0   8 194 386 645 528 724 291  46 777]]\n"
     ]
    }
   ],
   "source": [
    "# Define embedding parameters\n",
    "embedding_vector_features = 40\n",
    "max_length = 10\n",
    "# Pad the sequences to ensure uniform input size\n",
    "embedded_docs = pad_sequences(onehot_repr, maxlen=max_length, padding='pre')\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e48503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_vector_features, input_length=max_length))\n",
    "model.compile('adam', 'mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7d5c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04085955, -0.00650885, -0.0337347 ,  0.02015624,  0.04374831,\n",
       "         0.01932217, -0.01682113,  0.00903745, -0.01712758, -0.01383976,\n",
       "         0.02878686,  0.04850774,  0.03497646,  0.04919532,  0.04388291,\n",
       "        -0.03471887,  0.02767109, -0.02223736, -0.02858779,  0.04045634,\n",
       "         0.01914651,  0.04859788, -0.04721096,  0.00412831, -0.03574838,\n",
       "         0.02958072, -0.04116786, -0.03419014, -0.04401296, -0.00739042,\n",
       "        -0.03014123, -0.00412093,  0.04937177,  0.04400686, -0.04071405,\n",
       "         0.03592919, -0.02224927, -0.00727474, -0.00771062, -0.03736547],\n",
       "       [ 0.04085955, -0.00650885, -0.0337347 ,  0.02015624,  0.04374831,\n",
       "         0.01932217, -0.01682113,  0.00903745, -0.01712758, -0.01383976,\n",
       "         0.02878686,  0.04850774,  0.03497646,  0.04919532,  0.04388291,\n",
       "        -0.03471887,  0.02767109, -0.02223736, -0.02858779,  0.04045634,\n",
       "         0.01914651,  0.04859788, -0.04721096,  0.00412831, -0.03574838,\n",
       "         0.02958072, -0.04116786, -0.03419014, -0.04401296, -0.00739042,\n",
       "        -0.03014123, -0.00412093,  0.04937177,  0.04400686, -0.04071405,\n",
       "         0.03592919, -0.02224927, -0.00727474, -0.00771062, -0.03736547],\n",
       "       [-0.02572743, -0.04745301,  0.03690535, -0.01948485, -0.02229059,\n",
       "        -0.02304728, -0.02366865,  0.03083741,  0.04234872,  0.00770731,\n",
       "        -0.03216719, -0.03824191, -0.02958142,  0.04943274,  0.01337234,\n",
       "        -0.02718442,  0.01430998, -0.00310045,  0.02663031,  0.03433735,\n",
       "         0.0443189 ,  0.04773039, -0.04150925,  0.02910403, -0.01369975,\n",
       "        -0.00976503, -0.01220711,  0.04927761,  0.02672895,  0.02400043,\n",
       "        -0.00306343,  0.02669778, -0.04943583,  0.00925823, -0.04946725,\n",
       "         0.04120849,  0.04998943,  0.0017916 , -0.01211377, -0.04274426],\n",
       "       [ 0.02080864, -0.04108405, -0.04555158, -0.0159768 ,  0.03304256,\n",
       "         0.03929344,  0.03021494, -0.00861707,  0.00752226, -0.02866234,\n",
       "         0.03488971, -0.0078518 ,  0.00299925, -0.01095153, -0.0419773 ,\n",
       "         0.048921  ,  0.03659594,  0.03854874, -0.00223217, -0.03239303,\n",
       "        -0.00275955, -0.02302063, -0.0235953 , -0.01393449,  0.01061709,\n",
       "         0.04628002, -0.01545397, -0.01158144, -0.00388168, -0.00318806,\n",
       "         0.03615611, -0.02612338,  0.0065829 , -0.04086499,  0.04328744,\n",
       "        -0.04071788,  0.00252559,  0.04108329, -0.00451363,  0.03316874],\n",
       "       [-0.00825391, -0.03609889, -0.01552476,  0.00244726, -0.00668322,\n",
       "         0.04604732, -0.01139335,  0.00618004,  0.03303783,  0.02602876,\n",
       "        -0.03949722, -0.00863733,  0.00494362,  0.02536745, -0.02604022,\n",
       "         0.01628772, -0.03123349, -0.03101621,  0.01964954,  0.0138589 ,\n",
       "        -0.0209631 , -0.04499481, -0.01724575, -0.04500636,  0.01056483,\n",
       "        -0.04733748,  0.03560639,  0.03464911,  0.00673473, -0.00530608,\n",
       "         0.00690795, -0.04389348,  0.03916392,  0.00104326, -0.03195865,\n",
       "         0.02374209,  0.01118734, -0.03115317,  0.03192201, -0.01917385],\n",
       "       [ 0.02699282, -0.02220241, -0.00673772,  0.0264595 , -0.03753255,\n",
       "         0.02135858,  0.04261173, -0.01152607,  0.02095966, -0.01966343,\n",
       "         0.0352971 , -0.02974858, -0.03415909,  0.04850194,  0.03051243,\n",
       "        -0.00828863,  0.0010339 , -0.00689139,  0.04644057, -0.03639337,\n",
       "        -0.00781043,  0.01587688, -0.03694461,  0.00350306, -0.0348799 ,\n",
       "        -0.01405346,  0.01779049,  0.04386974,  0.02655815,  0.02564187,\n",
       "        -0.0235703 , -0.02876127,  0.03005886,  0.01972962, -0.02606617,\n",
       "        -0.03788382, -0.01347654, -0.02830498, -0.03158181,  0.01939226],\n",
       "       [ 0.03574297, -0.03868727,  0.0116554 ,  0.0259256 ,  0.020185  ,\n",
       "        -0.00459092, -0.00603533,  0.00026602, -0.00982901, -0.03640063,\n",
       "        -0.04904228,  0.02679534, -0.01374726,  0.02230755,  0.00584789,\n",
       "        -0.04721173,  0.03293159, -0.04860406,  0.00136613, -0.03487278,\n",
       "        -0.01717862,  0.02170119, -0.03794582,  0.01196252,  0.02897825,\n",
       "         0.0176377 , -0.02175744,  0.00196882, -0.02792293,  0.01785406,\n",
       "         0.02818732, -0.01052205,  0.01954169, -0.02150927, -0.01494586,\n",
       "         0.0110613 , -0.02188121, -0.03403188, -0.0463866 ,  0.02747412],\n",
       "       [-0.04409716,  0.02119454,  0.0306713 ,  0.00093674, -0.00288181,\n",
       "         0.01900265, -0.04560486,  0.01154699,  0.04121174,  0.00220976,\n",
       "         0.00529001,  0.01088905, -0.00211154, -0.01763183, -0.04774469,\n",
       "         0.03884938,  0.00336032, -0.00939266,  0.02708037,  0.02614881,\n",
       "         0.01829043,  0.03225842,  0.03538922, -0.0301113 ,  0.04682816,\n",
       "        -0.03486891,  0.01068542,  0.02728673, -0.04468435,  0.01431278,\n",
       "        -0.017765  ,  0.02782794,  0.02310931, -0.03094997, -0.00752958,\n",
       "        -0.01486049,  0.02863475, -0.04762927,  0.01601452,  0.00354328],\n",
       "       [-0.03343856,  0.01355035, -0.0459278 ,  0.0316675 , -0.02658495,\n",
       "         0.00038671,  0.01857055,  0.04745628,  0.01448201, -0.04592275,\n",
       "         0.02883938,  0.01576759, -0.0453602 , -0.04412942,  0.02518875,\n",
       "        -0.02673249, -0.02004855, -0.03804259,  0.02038028, -0.02555652,\n",
       "        -0.00088032, -0.01930807,  0.02229932,  0.00530542,  0.00690105,\n",
       "         0.02656503, -0.00565844, -0.02988651,  0.02673734, -0.03662281,\n",
       "         0.03873566,  0.04034546, -0.04381675,  0.01246818,  0.01086769,\n",
       "        -0.019526  , -0.04469007,  0.02677876,  0.00849982, -0.03531364],\n",
       "       [ 0.02080864, -0.04108405, -0.04555158, -0.0159768 ,  0.03304256,\n",
       "         0.03929344,  0.03021494, -0.00861707,  0.00752226, -0.02866234,\n",
       "         0.03488971, -0.0078518 ,  0.00299925, -0.01095153, -0.0419773 ,\n",
       "         0.048921  ,  0.03659594,  0.03854874, -0.00223217, -0.03239303,\n",
       "        -0.00275955, -0.02302063, -0.0235953 , -0.01393449,  0.01061709,\n",
       "         0.04628002, -0.01545397, -0.01158144, -0.00388168, -0.00318806,\n",
       "         0.03615611, -0.02612338,  0.0065829 , -0.04086499,  0.04328744,\n",
       "        -0.04071788,  0.00252559,  0.04108329, -0.00451363,  0.03316874]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d610571f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— python setup.py egg_info did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [44 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 35, in __init__\n",
      "          parsed = _parse_requirement(requirement_string)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 64, in parse_requirement\n",
      "          return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 82, in _parse_requirement\n",
      "          url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 126, in _parse_requirement_details\n",
      "          marker = _parse_requirement_marker(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_parser.py\", line 147, in _parse_requirement_marker\n",
      "          tokenizer.raise_syntax_error(\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\_tokenizer.py\", line 165, in raise_syntax_error\n",
      "          raise ParserSyntaxError(\n",
      "      setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\AppData\\Local\\Temp\\pip-install-1g3m6_0c\\tensorflow-gpu_30040e60d1af4ae29b7f23e673775cee\\setup.py\", line 40, in <module>\n",
      "          setuptools.setup()\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 102, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py\", line 73, in _install_setup_requires\n",
      "          dist.parse_config_files(ignore_option_errors=True)\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 655, in parse_config_files\n",
      "          self._finalize_requires()\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 390, in _finalize_requires\n",
      "          self._normalize_requires()\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\dist.py\", line 405, in _normalize_requires\n",
      "          self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\setuptools\\_vendor\\packaging\\requirements.py\", line 37, in __init__\n",
      "          raise InvalidRequirement(str(e)) from e\n",
      "      setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "          python_version>\"3.7\"\n",
      "                        ^\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Ã— Encountered error while generating package metadata.\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f5ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU check: []\n",
      "âš ï¸ GPU not found. TensorFlow is stuck with the CPU.\n",
      "Check your NVIDIA driver, CUDA, and cuDNN setup. Good luck.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# This command lists all physical devices TensorFlow can see\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"TensorFlow GPU check:\", devices)\n",
    "if len(devices) > 0:\n",
    "    print(f\"ğŸš€ Success! Found {len(devices)} GPU(s):\")\n",
    "    for device in devices:\n",
    "        print(f\"  - {device}\")\n",
    "else:\n",
    "    print(\"âš ï¸ GPU not found. TensorFlow is stuck with the CPU.\")\n",
    "    print(\"Check your NVIDIA driver, CUDA, and cuDNN setup. Good luck.\")\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e69f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Success! Found 1 GPU(s):\n",
      "  - NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ğŸš€ Success! Found {torch.cuda.device_count()} GPU(s):\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  - {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491b98d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\Raj Kalash Tiwari\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: \"'tensorflow[and-cuda]'\": Expected package name at the start of dependency specifier\n",
      "    'tensorflow[and-cuda]'\n",
      "    ^\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install 'tensorflow[and-cuda]'\n",
    "# Verify the installation:\n",
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33163729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (2.3.1)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow[and-cuda])\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (25.9.23)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow[and-cuda])\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow[and-cuda])\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow[and-cuda])\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow[and-cuda])\n",
      "  Using cached protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Collecting setuptools (from tensorflow[and-cuda])\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow[and-cuda])\n",
      "  Using cached termcolor-3.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (1.17.3)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow[and-cuda])\n",
      "  Using cached grpcio-1.76.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow[and-cuda])\n",
      "  Using cached keras-3.12.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow[and-cuda])\n",
      "  Using cached h5py-3.15.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (0.5.3)\n",
      "Collecting nvidia-cublas-cu12<13.0,>=12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.14.0.64-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cufft-cu12<12.0,>=11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.4.1.4-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand-cu12<11.0,>=10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.10.19-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12<12.0,>=11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cusparse-cu12<13.0,>=12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.19.1-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\raj kalash tiwari\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow[and-cuda]) (4.25.8)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.5.3.2-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.3.0.75-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.2.3.61-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.6.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.6.3.83-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.1.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "  Using cached tensorflow-2.18.1-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.17.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.4.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    tensorflow[and-cuda] 2.20.0 depends on nvidia-nccl-cu12<3.0 and >=2.25.1; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.19.1 depends on nvidia-nccl-cu12==2.23.4; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.19.0 depends on nvidia-nccl-cu12==2.23.4; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.18.1 depends on nvidia-nccl-cu12==2.21.5; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.18.0 depends on nvidia-nccl-cu12==2.21.5; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.0 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.2 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "\n",
      "Additionally, some packages in these conflicts have no matching distributions available for your environment:\n",
      "    nvidia-nccl-cu12\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install tensorflow[and-cuda]==2.16.1, tensorflow[and-cuda]==2.16.2, tensorflow[and-cuda]==2.17.0, tensorflow[and-cuda]==2.17.1, tensorflow[and-cuda]==2.18.0, tensorflow[and-cuda]==2.18.1, tensorflow[and-cuda]==2.19.0, tensorflow[and-cuda]==2.19.1 and tensorflow[and-cuda]==2.20.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "ModuleNotFoundError: No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install tensorflow[and-cuda]\n",
    "# Verify the installation:\n",
    "!python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97611476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "driver= tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d2ac724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Number of devices: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define strategy\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print(f'Number of devices: {strategy.num_replicas_in_sync}')\n",
    "\n",
    "# Create model within strategy scope\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37f8126e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Check which device operations are running on\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create a tensor and check device placement\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d7a5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs found:  []\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Raj Kalash Tiwari\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.3229 - val_accuracy: 0.9607 - val_loss: 0.1304\n",
      "Epoch 2/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9632 - loss: 0.1213 - val_accuracy: 0.9736 - val_loss: 0.0870\n",
      "Epoch 3/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9741 - loss: 0.0827 - val_accuracy: 0.9776 - val_loss: 0.0749\n",
      "Epoch 4/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9797 - loss: 0.0638 - val_accuracy: 0.9799 - val_loss: 0.0646\n",
      "Epoch 5/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0501 - val_accuracy: 0.9806 - val_loss: 0.0618\n",
      "Epoch 6/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0433 - val_accuracy: 0.9819 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9887 - loss: 0.0355 - val_accuracy: 0.9812 - val_loss: 0.0654\n",
      "Epoch 8/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0300 - val_accuracy: 0.9814 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9910 - loss: 0.0275 - val_accuracy: 0.9820 - val_loss: 0.0641\n",
      "Epoch 10/10\n",
      "\u001b[1m235/235\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0235 - val_accuracy: 0.9815 - val_loss: 0.0616\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Enable memory growth for GPUs\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"GPUs found: \", gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Create synthetic data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "x_test = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# Use multi-GPU strategy if available\n",
    "if len(tf.config.experimental.list_physical_devices('GPU')) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=10,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53647701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "\n",
      "Available devices:\n",
      " - PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "\n",
      "Number of GPUs detected: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Check what devices are available\n",
    "print(\"\\nAvailable devices:\")\n",
    "for device in tf.config.list_physical_devices():\n",
    "    print(f\" - {device}\")\n",
    "\n",
    "# Specifically check for GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nNumber of GPUs detected: {len(gpus)}\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(f\"GPU: {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Uninstall current version and install with CUDA support\n",
    "!pip uninstall tensorflow\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866deb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using optimized CPU configuration\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Using optimized CPU configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7bf7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
